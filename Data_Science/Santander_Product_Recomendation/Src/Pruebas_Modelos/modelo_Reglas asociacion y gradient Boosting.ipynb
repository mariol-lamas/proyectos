{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data Viz \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data Manipulation\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# Similarity calculation\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Import ML libraries\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.linalg import svds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4f/gbmqzwn51yg8gh7yyxzgpcl80000gn/T/ipykernel_1550/848381883.py:2: DtypeWarning: Columns (4,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data=pd.read_csv('../../Data/Limpio/dataset_limpio_parte1.csv')\n",
      "/var/folders/4f/gbmqzwn51yg8gh7yyxzgpcl80000gn/T/ipykernel_1550/848381883.py:3: DtypeWarning: Columns (4,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data1=pd.read_csv('../../Data/Limpio/dataset_limpio_parte2.csv')\n",
      "/var/folders/4f/gbmqzwn51yg8gh7yyxzgpcl80000gn/T/ipykernel_1550/848381883.py:4: DtypeWarning: Columns (4,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data2=pd.read_csv('../../Data/Limpio/dataset_limpio_parte3.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cod_persona</th>\n",
       "      <th>mes</th>\n",
       "      <th>pais</th>\n",
       "      <th>sexo</th>\n",
       "      <th>edad</th>\n",
       "      <th>fecha1</th>\n",
       "      <th>xti_empleado</th>\n",
       "      <th>xti_nuevo_cliente</th>\n",
       "      <th>num_antiguedad</th>\n",
       "      <th>xti_rel</th>\n",
       "      <th>...</th>\n",
       "      <th>ind_prod16</th>\n",
       "      <th>ind_prod17</th>\n",
       "      <th>ind_prod18</th>\n",
       "      <th>ind_prod19</th>\n",
       "      <th>ind_prod20</th>\n",
       "      <th>ind_prod21</th>\n",
       "      <th>ind_prod22</th>\n",
       "      <th>ind_prod23</th>\n",
       "      <th>ind_prod24</th>\n",
       "      <th>ind_prod25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5514</td>\n",
       "      <td>2016-04-28</td>\n",
       "      <td>ES</td>\n",
       "      <td>H</td>\n",
       "      <td>44</td>\n",
       "      <td>2016-04-29</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5541</td>\n",
       "      <td>2016-04-28</td>\n",
       "      <td>ES</td>\n",
       "      <td>H</td>\n",
       "      <td>60</td>\n",
       "      <td>2016-04-29</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631</td>\n",
       "      <td>2016-04-28</td>\n",
       "      <td>ES</td>\n",
       "      <td>V</td>\n",
       "      <td>53</td>\n",
       "      <td>2016-04-28</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5656</td>\n",
       "      <td>2016-04-28</td>\n",
       "      <td>ES</td>\n",
       "      <td>H</td>\n",
       "      <td>47</td>\n",
       "      <td>2016-04-28</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5738</td>\n",
       "      <td>2016-04-28</td>\n",
       "      <td>ES</td>\n",
       "      <td>V</td>\n",
       "      <td>48</td>\n",
       "      <td>2016-04-28</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cod_persona         mes pais sexo edad      fecha1 xti_empleado  \\\n",
       "0         5514  2016-04-28   ES    H   44  2016-04-29            N   \n",
       "1         5541  2016-04-28   ES    H   60  2016-04-29            N   \n",
       "2         5631  2016-04-28   ES    V   53  2016-04-28            N   \n",
       "3         5656  2016-04-28   ES    H   47  2016-04-28            N   \n",
       "4         5738  2016-04-28   ES    V   48  2016-04-28            N   \n",
       "\n",
       "   xti_nuevo_cliente num_antiguedad  xti_rel  ... ind_prod16 ind_prod17  \\\n",
       "0                1.0              0      1.0  ...          0          0   \n",
       "1                1.0              0      1.0  ...          0          0   \n",
       "2                1.0              0      1.0  ...          0          0   \n",
       "3                1.0              0      1.0  ...          0          0   \n",
       "4                1.0              0      1.0  ...          0          0   \n",
       "\n",
       "  ind_prod18 ind_prod19 ind_prod20  ind_prod21  ind_prod22  ind_prod23  \\\n",
       "0          0          0          0           0         0.0         0.0   \n",
       "1          0          0          0           0         0.0         0.0   \n",
       "2          0          0          0           0         0.0         0.0   \n",
       "3          0          0          0           0         0.0         0.0   \n",
       "4          0          0          0           0         0.0         0.0   \n",
       "\n",
       "   ind_prod24 ind_prod25  \n",
       "0           0          0  \n",
       "1           0          0  \n",
       "2           0          0  \n",
       "3           0          0  \n",
       "4           0          0  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Supongamos que 'data' es el DataFrame cargado con las columnas descritas\n",
    "data=pd.read_csv('../../Data/Limpio/dataset_limpio_parte1.csv')\n",
    "data1=pd.read_csv('../../Data/Limpio/dataset_limpio_parte2.csv')\n",
    "data2=pd.read_csv('../../Data/Limpio/dataset_limpio_parte3.csv')\n",
    "data_unida=pd.concat([data,data1,data2]) # Ajusta el nombre del archivo según corresponda\n",
    "data_unida.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds=[f'ind_prod{i}' for i in range(1,26)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_unida[inds] = data_unida[inds].astype(bool)\n",
    "\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "frequent_itemsets = apriori(data_unida[inds], min_support=0.01, use_colnames=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "      <th>zhangs_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(ind_prod8)</td>\n",
       "      <td>(ind_prod3)</td>\n",
       "      <td>0.131909</td>\n",
       "      <td>0.660945</td>\n",
       "      <td>0.087759</td>\n",
       "      <td>0.665301</td>\n",
       "      <td>1.006590</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>1.013014</td>\n",
       "      <td>0.007542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(ind_prod3)</td>\n",
       "      <td>(ind_prod8)</td>\n",
       "      <td>0.660945</td>\n",
       "      <td>0.131909</td>\n",
       "      <td>0.087759</td>\n",
       "      <td>0.132778</td>\n",
       "      <td>1.006590</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>1.001002</td>\n",
       "      <td>0.019310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(ind_prod12)</td>\n",
       "      <td>(ind_prod3)</td>\n",
       "      <td>0.043438</td>\n",
       "      <td>0.660945</td>\n",
       "      <td>0.030423</td>\n",
       "      <td>0.700388</td>\n",
       "      <td>1.059677</td>\n",
       "      <td>0.001713</td>\n",
       "      <td>1.131647</td>\n",
       "      <td>0.058873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(ind_prod3)</td>\n",
       "      <td>(ind_prod12)</td>\n",
       "      <td>0.660945</td>\n",
       "      <td>0.043438</td>\n",
       "      <td>0.030423</td>\n",
       "      <td>0.046030</td>\n",
       "      <td>1.059677</td>\n",
       "      <td>0.001713</td>\n",
       "      <td>1.002717</td>\n",
       "      <td>0.166097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(ind_prod14)</td>\n",
       "      <td>(ind_prod3)</td>\n",
       "      <td>0.018698</td>\n",
       "      <td>0.660945</td>\n",
       "      <td>0.012438</td>\n",
       "      <td>0.665206</td>\n",
       "      <td>1.006447</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>1.012727</td>\n",
       "      <td>0.006527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>(ind_prod23)</td>\n",
       "      <td>(ind_prod25, ind_prod24, ind_prod22, ind_prod5...</td>\n",
       "      <td>0.060312</td>\n",
       "      <td>0.016901</td>\n",
       "      <td>0.016901</td>\n",
       "      <td>0.280232</td>\n",
       "      <td>16.580423</td>\n",
       "      <td>0.015882</td>\n",
       "      <td>1.365855</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1518</th>\n",
       "      <td>(ind_prod24)</td>\n",
       "      <td>(ind_prod25, ind_prod23, ind_prod22, ind_prod5...</td>\n",
       "      <td>0.128827</td>\n",
       "      <td>0.018687</td>\n",
       "      <td>0.016901</td>\n",
       "      <td>0.131195</td>\n",
       "      <td>7.020817</td>\n",
       "      <td>0.014494</td>\n",
       "      <td>1.129498</td>\n",
       "      <td>0.984381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519</th>\n",
       "      <td>(ind_prod22)</td>\n",
       "      <td>(ind_prod25, ind_prod23, ind_prod24, ind_prod5...</td>\n",
       "      <td>0.055570</td>\n",
       "      <td>0.018212</td>\n",
       "      <td>0.016901</td>\n",
       "      <td>0.304148</td>\n",
       "      <td>16.700176</td>\n",
       "      <td>0.015889</td>\n",
       "      <td>1.410915</td>\n",
       "      <td>0.995436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520</th>\n",
       "      <td>(ind_prod5)</td>\n",
       "      <td>(ind_prod25, ind_prod23, ind_prod24, ind_prod2...</td>\n",
       "      <td>0.081740</td>\n",
       "      <td>0.017699</td>\n",
       "      <td>0.016901</td>\n",
       "      <td>0.206770</td>\n",
       "      <td>11.682804</td>\n",
       "      <td>0.015455</td>\n",
       "      <td>1.238356</td>\n",
       "      <td>0.995801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>(ind_prod19)</td>\n",
       "      <td>(ind_prod25, ind_prod23, ind_prod24, ind_prod2...</td>\n",
       "      <td>0.045505</td>\n",
       "      <td>0.018825</td>\n",
       "      <td>0.016901</td>\n",
       "      <td>0.371421</td>\n",
       "      <td>19.729997</td>\n",
       "      <td>0.016045</td>\n",
       "      <td>1.560940</td>\n",
       "      <td>0.994574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1522 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       antecedents                                        consequents  \\\n",
       "0      (ind_prod8)                                        (ind_prod3)   \n",
       "1      (ind_prod3)                                        (ind_prod8)   \n",
       "2     (ind_prod12)                                        (ind_prod3)   \n",
       "3      (ind_prod3)                                       (ind_prod12)   \n",
       "4     (ind_prod14)                                        (ind_prod3)   \n",
       "...            ...                                                ...   \n",
       "1517  (ind_prod23)  (ind_prod25, ind_prod24, ind_prod22, ind_prod5...   \n",
       "1518  (ind_prod24)  (ind_prod25, ind_prod23, ind_prod22, ind_prod5...   \n",
       "1519  (ind_prod22)  (ind_prod25, ind_prod23, ind_prod24, ind_prod5...   \n",
       "1520   (ind_prod5)  (ind_prod25, ind_prod23, ind_prod24, ind_prod2...   \n",
       "1521  (ind_prod19)  (ind_prod25, ind_prod23, ind_prod24, ind_prod2...   \n",
       "\n",
       "      antecedent support  consequent support   support  confidence       lift  \\\n",
       "0               0.131909            0.660945  0.087759    0.665301   1.006590   \n",
       "1               0.660945            0.131909  0.087759    0.132778   1.006590   \n",
       "2               0.043438            0.660945  0.030423    0.700388   1.059677   \n",
       "3               0.660945            0.043438  0.030423    0.046030   1.059677   \n",
       "4               0.018698            0.660945  0.012438    0.665206   1.006447   \n",
       "...                  ...                 ...       ...         ...        ...   \n",
       "1517            0.060312            0.016901  0.016901    0.280232  16.580423   \n",
       "1518            0.128827            0.018687  0.016901    0.131195   7.020817   \n",
       "1519            0.055570            0.018212  0.016901    0.304148  16.700176   \n",
       "1520            0.081740            0.017699  0.016901    0.206770  11.682804   \n",
       "1521            0.045505            0.018825  0.016901    0.371421  19.729997   \n",
       "\n",
       "      leverage  conviction  zhangs_metric  \n",
       "0     0.000575    1.013014       0.007542  \n",
       "1     0.000575    1.001002       0.019310  \n",
       "2     0.001713    1.131647       0.058873  \n",
       "3     0.001713    1.002717       0.166097  \n",
       "4     0.000080    1.012727       0.006527  \n",
       "...        ...         ...            ...  \n",
       "1517  0.015882    1.365855       1.000000  \n",
       "1518  0.014494    1.129498       0.984381  \n",
       "1519  0.015889    1.410915       0.995436  \n",
       "1520  0.015455    1.238356       0.995801  \n",
       "1521  0.016045    1.560940       0.994574  \n",
       "\n",
       "[1522 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\n",
    "\n",
    "# Display the association rules\n",
    "rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_unida.loc[data_unida['edad']==' NA','edad']=f\"{data_unida['edad'].str.replace(' NA','0').median()}\"\n",
    "data_unida.loc[data_unida['num_antiguedad']=='     NA','num_antiguedad']=f\"{data_unida['num_antiguedad'].str.replace('     NA','0').median()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4f/gbmqzwn51yg8gh7yyxzgpcl80000gn/T/ipykernel_1550/3402631540.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['edad']=data['edad'].astype(float)\n",
      "/var/folders/4f/gbmqzwn51yg8gh7yyxzgpcl80000gn/T/ipykernel_1550/3402631540.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['num_antiguedad']=data['num_antiguedad'].astype(float)\n",
      "/var/folders/4f/gbmqzwn51yg8gh7yyxzgpcl80000gn/T/ipykernel_1550/3402631540.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['fecha1'] = pd.to_datetime(data['fecha1'])\n",
      "/var/folders/4f/gbmqzwn51yg8gh7yyxzgpcl80000gn/T/ipykernel_1550/3402631540.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['mes'] = pd.to_datetime(data['mes'])\n"
     ]
    }
   ],
   "source": [
    "data=data_unida[~data_unida['fecha1'].isna()]\n",
    "data['edad']=data['edad'].astype(float)\n",
    "data['num_antiguedad']=data['num_antiguedad'].astype(float)\n",
    "data['fecha1'] = pd.to_datetime(data['fecha1'])\n",
    "data['mes'] = pd.to_datetime(data['mes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dummy = data.select_dtypes(include = 'O')\n",
    "train_dummy = pd.get_dummies(train_dummy)\n",
    "X=train_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariolamas/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/mariolamas/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/mariolamas/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/mariolamas/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariolamas/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/mariolamas/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/mariolamas/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/mariolamas/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/mariolamas/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariolamas/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/mariolamas/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/mariolamas/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariolamas/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/mariolamas/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/mariolamas/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariolamas/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/mariolamas/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/mariolamas/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariolamas/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/mariolamas/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/mariolamas/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariolamas/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/mariolamas/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/mariolamas/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariolamas/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/mariolamas/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/mariolamas/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/mariolamas/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/mariolamas/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariolamas/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/mariolamas/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/mariolamas/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariolamas/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/mariolamas/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/mariolamas/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariolamas/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/mariolamas/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/mariolamas/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariolamas/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/mariolamas/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/mariolamas/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariolamas/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/mariolamas/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/mariolamas/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/mariolamas/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/mariolamas/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariolamas/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 15\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Train the GBDT model\u001b[39;00m\n\u001b[1;32m     11\u001b[0m gbdt_model \u001b[38;5;241m=\u001b[39m GradientBoostingClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m,  \u001b[38;5;66;03m# Number of boosting stages\u001b[39;00m\n\u001b[1;32m     12\u001b[0m                                    learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,  \u001b[38;5;66;03m# Learning rate\u001b[39;00m\n\u001b[1;32m     13\u001b[0m                                    max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,  \u001b[38;5;66;03m# Maximum depth of each tree\u001b[39;00m\n\u001b[1;32m     14\u001b[0m                                    random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m123\u001b[39m) \n\u001b[0;32m---> 15\u001b[0m \u001b[43mgbdt_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Generate GBDT features\u001b[39;00m\n\u001b[1;32m     17\u001b[0m gbdt_features \u001b[38;5;241m=\u001b[39m gbdt_model\u001b[38;5;241m.\u001b[39mapply(X_train)[:, :, \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/sklearn/ensemble/_gb.py:784\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    781\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resize_state()\n\u001b[1;32m    783\u001b[0m \u001b[38;5;66;03m# fit the boosting stages\u001b[39;00m\n\u001b[0;32m--> 784\u001b[0m n_stages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stages\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbegin_at_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[38;5;66;03m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[1;32m    798\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_stages \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[0;32m~/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/sklearn/ensemble/_gb.py:880\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[1;32m    873\u001b[0m         initial_loss \u001b[38;5;241m=\u001b[39m factor \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loss(\n\u001b[1;32m    874\u001b[0m             y_true\u001b[38;5;241m=\u001b[39my_oob_masked,\n\u001b[1;32m    875\u001b[0m             raw_prediction\u001b[38;5;241m=\u001b[39mraw_predictions[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[1;32m    876\u001b[0m             sample_weight\u001b[38;5;241m=\u001b[39msample_weight_oob_masked,\n\u001b[1;32m    877\u001b[0m         )\n\u001b[1;32m    879\u001b[0m \u001b[38;5;66;03m# fit next stage of trees\u001b[39;00m\n\u001b[0;32m--> 880\u001b[0m raw_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_csc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_csr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[38;5;66;03m# track loss\u001b[39;00m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_oob:\n",
      "File \u001b[0;32m~/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/sklearn/ensemble/_gb.py:490\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    487\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;241m*\u001b[39m sample_mask\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m    489\u001b[0m X \u001b[38;5;241m=\u001b[39m X_csc \u001b[38;5;28;01mif\u001b[39;00m X_csc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\n\u001b[0;32m--> 490\u001b[0m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneg_g_view\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    492\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;66;03m# update tree leaves\u001b[39;00m\n\u001b[1;32m    495\u001b[0m X_for_tree_update \u001b[38;5;241m=\u001b[39m X_csr \u001b[38;5;28;01mif\u001b[39;00m X_csr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\n",
      "File \u001b[0;32m~/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/sklearn/tree/_classes.py:1377\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   1349\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[1;32m   1350\u001b[0m \n\u001b[1;32m   1351\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1374\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1377\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1378\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1379\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1380\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1381\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1382\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/sklearn/tree/_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    463\u001b[0m         splitter,\n\u001b[1;32m    464\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    470\u001b[0m     )\n\u001b[0;32m--> 472\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pred = {}\n",
    "for i in inds:\n",
    "    \n",
    "    # Use the target product column as the target variable\n",
    "    if data[i].nunique() == 2:\n",
    "        \n",
    "        y = data[i] \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "    \n",
    "        # Train the GBDT model\n",
    "        gbdt_model = GradientBoostingClassifier(n_estimators=300,  # Number of boosting stages\n",
    "                                           learning_rate=0.1,  # Learning rate\n",
    "                                           max_depth=3,  # Maximum depth of each tree\n",
    "                                           random_state=123) \n",
    "        gbdt_model.fit(X_train, y_train)\n",
    "        # Generate GBDT features\n",
    "        gbdt_features = gbdt_model.apply(X_train)[:, :, 0]\n",
    "    \n",
    "        # Train the LR model using the GBDT generated features\n",
    "        lr_model = LogisticRegression(solver='lbfgs', C=1.0, random_state=123)\n",
    "\n",
    "        lr_model.fit(gbdt_features, y_train)\n",
    "    \n",
    "        # Generate LR features\n",
    "        gbdt_features_test = gbdt_model.apply(X_test)[:, :, 0]\n",
    "        lr_features = lr_model.predict_proba(gbdt_features_test)[:, 1]\n",
    "    \n",
    "        # Store the predicted score for the product\n",
    "        pred[i] = lr_features\n",
    "        \n",
    "    else: \n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(pred)\n",
    "test_gbdt = pd.concat([X_test.reset_index(names = 'cod_persona'), pred],axis = 1, ignore_index = True)\n",
    "\n",
    "col_list = ['cod_persona'] + list(X_test.columns) + list(pred.columns)\n",
    "test_gbdt.columns = col_list\n",
    "test_gbdt['cod_persona'] = test_gbdt['cod_persona'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ind_prod1</th>\n",
       "      <th>ind_prod3</th>\n",
       "      <th>ind_prod4</th>\n",
       "      <th>ind_prod5</th>\n",
       "      <th>ind_prod6</th>\n",
       "      <th>ind_prod7</th>\n",
       "      <th>ind_prod8</th>\n",
       "      <th>ind_prod9</th>\n",
       "      <th>ind_prod10</th>\n",
       "      <th>ind_prod11</th>\n",
       "      <th>...</th>\n",
       "      <th>ind_prod16</th>\n",
       "      <th>ind_prod17</th>\n",
       "      <th>ind_prod18</th>\n",
       "      <th>ind_prod19</th>\n",
       "      <th>ind_prod20</th>\n",
       "      <th>ind_prod21</th>\n",
       "      <th>ind_prod22</th>\n",
       "      <th>ind_prod23</th>\n",
       "      <th>ind_prod24</th>\n",
       "      <th>ind_prod25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86466</th>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.860458</td>\n",
       "      <td>2.000951e-13</td>\n",
       "      <td>0.001358</td>\n",
       "      <td>5.161358e-08</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>1.667442e-08</td>\n",
       "      <td>2.912892e-09</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>7.538930e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>1.904755e-07</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>7.687415e-14</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.000778</td>\n",
       "      <td>0.003001</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73365</th>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.366057</td>\n",
       "      <td>7.142495e-12</td>\n",
       "      <td>0.002320</td>\n",
       "      <td>9.009478e-06</td>\n",
       "      <td>0.006367</td>\n",
       "      <td>5.788504e-02</td>\n",
       "      <td>1.748872e-02</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>1.833737e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.024248e-04</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>0.050684</td>\n",
       "      <td>0.001055</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>2.588881e-03</td>\n",
       "      <td>0.000932</td>\n",
       "      <td>0.001426</td>\n",
       "      <td>0.005181</td>\n",
       "      <td>0.000758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21207</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.662489</td>\n",
       "      <td>3.497493e-03</td>\n",
       "      <td>0.260821</td>\n",
       "      <td>8.415187e-06</td>\n",
       "      <td>0.044133</td>\n",
       "      <td>2.524754e-01</td>\n",
       "      <td>1.268099e-01</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>1.986978e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>6.667724e-02</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.174465</td>\n",
       "      <td>0.204871</td>\n",
       "      <td>0.236651</td>\n",
       "      <td>9.471727e-03</td>\n",
       "      <td>0.181751</td>\n",
       "      <td>0.216862</td>\n",
       "      <td>0.377196</td>\n",
       "      <td>0.335571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93807</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.896160</td>\n",
       "      <td>1.071665e-06</td>\n",
       "      <td>0.078632</td>\n",
       "      <td>1.376585e-07</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>1.203097e-07</td>\n",
       "      <td>1.541232e-08</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>3.212945e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>8.865389e-06</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.011322</td>\n",
       "      <td>0.006860</td>\n",
       "      <td>0.001785</td>\n",
       "      <td>4.005483e-14</td>\n",
       "      <td>0.044988</td>\n",
       "      <td>0.044098</td>\n",
       "      <td>0.151164</td>\n",
       "      <td>0.009193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48285</th>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.850251</td>\n",
       "      <td>1.339145e-13</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>8.144947e-08</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>1.535230e-08</td>\n",
       "      <td>2.912892e-09</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>7.538930e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>1.909322e-07</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.004141</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>3.851401e-14</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.003514</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125305</th>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.709427</td>\n",
       "      <td>1.926340e-03</td>\n",
       "      <td>0.172217</td>\n",
       "      <td>3.466013e-02</td>\n",
       "      <td>0.023083</td>\n",
       "      <td>2.296479e-01</td>\n",
       "      <td>8.268969e-02</td>\n",
       "      <td>0.002951</td>\n",
       "      <td>3.942750e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>2.143078e-02</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>0.118701</td>\n",
       "      <td>0.107853</td>\n",
       "      <td>0.052832</td>\n",
       "      <td>5.641094e-03</td>\n",
       "      <td>0.121113</td>\n",
       "      <td>0.129586</td>\n",
       "      <td>0.300861</td>\n",
       "      <td>0.160262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65848</th>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.860458</td>\n",
       "      <td>2.000951e-13</td>\n",
       "      <td>0.001358</td>\n",
       "      <td>5.161358e-08</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>1.667442e-08</td>\n",
       "      <td>2.912892e-09</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>7.538930e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>1.904755e-07</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>7.687415e-14</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.000778</td>\n",
       "      <td>0.003001</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93129</th>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.366057</td>\n",
       "      <td>7.142495e-12</td>\n",
       "      <td>0.002320</td>\n",
       "      <td>9.009478e-06</td>\n",
       "      <td>0.006367</td>\n",
       "      <td>5.788504e-02</td>\n",
       "      <td>1.748872e-02</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>1.833737e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.024248e-04</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>0.050684</td>\n",
       "      <td>0.001055</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>2.588881e-03</td>\n",
       "      <td>0.000932</td>\n",
       "      <td>0.001426</td>\n",
       "      <td>0.005181</td>\n",
       "      <td>0.000758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88807</th>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.719794</td>\n",
       "      <td>1.116947e-06</td>\n",
       "      <td>0.222643</td>\n",
       "      <td>1.238510e-04</td>\n",
       "      <td>0.012726</td>\n",
       "      <td>1.035671e-01</td>\n",
       "      <td>4.621982e-02</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>1.642187e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.111746e-02</td>\n",
       "      <td>0.001146</td>\n",
       "      <td>0.077085</td>\n",
       "      <td>0.095228</td>\n",
       "      <td>0.016989</td>\n",
       "      <td>1.683617e-07</td>\n",
       "      <td>0.158837</td>\n",
       "      <td>0.223802</td>\n",
       "      <td>0.402286</td>\n",
       "      <td>0.116910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84402</th>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.678763</td>\n",
       "      <td>2.300784e-04</td>\n",
       "      <td>0.106120</td>\n",
       "      <td>3.849793e-05</td>\n",
       "      <td>0.049933</td>\n",
       "      <td>1.114182e-03</td>\n",
       "      <td>2.857292e-05</td>\n",
       "      <td>0.027544</td>\n",
       "      <td>2.605978e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>2.371912e-07</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.006308</td>\n",
       "      <td>0.004537</td>\n",
       "      <td>8.015374e-04</td>\n",
       "      <td>0.053569</td>\n",
       "      <td>0.072673</td>\n",
       "      <td>0.179578</td>\n",
       "      <td>0.011020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ind_prod1  ind_prod3     ind_prod4  ind_prod5     ind_prod6  \\\n",
       "86466    0.000006   0.860458  2.000951e-13   0.001358  5.161358e-08   \n",
       "73365    0.000151   0.366057  7.142495e-12   0.002320  9.009478e-06   \n",
       "21207    0.000002   0.662489  3.497493e-03   0.260821  8.415187e-06   \n",
       "93807    0.000002   0.896160  1.071665e-06   0.078632  1.376585e-07   \n",
       "48285    0.000006   0.850251  1.339145e-13   0.001400  8.144947e-08   \n",
       "125305   0.000014   0.709427  1.926340e-03   0.172217  3.466013e-02   \n",
       "65848    0.000006   0.860458  2.000951e-13   0.001358  5.161358e-08   \n",
       "93129    0.000151   0.366057  7.142495e-12   0.002320  9.009478e-06   \n",
       "88807    0.000019   0.719794  1.116947e-06   0.222643  1.238510e-04   \n",
       "84402    0.000014   0.678763  2.300784e-04   0.106120  3.849793e-05   \n",
       "\n",
       "        ind_prod7     ind_prod8     ind_prod9  ind_prod10    ind_prod11  ...  \\\n",
       "86466    0.000161  1.667442e-08  2.912892e-09    0.000002  7.538930e-08  ...   \n",
       "73365    0.006367  5.788504e-02  1.748872e-02    0.000026  1.833737e-06  ...   \n",
       "21207    0.044133  2.524754e-01  1.268099e-01    0.002844  1.986978e-02  ...   \n",
       "93807    0.000354  1.203097e-07  1.541232e-08    0.000090  3.212945e-06  ...   \n",
       "48285    0.000182  1.535230e-08  2.912892e-09    0.000002  7.538930e-08  ...   \n",
       "125305   0.023083  2.296479e-01  8.268969e-02    0.002951  3.942750e-03  ...   \n",
       "65848    0.000161  1.667442e-08  2.912892e-09    0.000002  7.538930e-08  ...   \n",
       "93129    0.006367  5.788504e-02  1.748872e-02    0.000026  1.833737e-06  ...   \n",
       "88807    0.012726  1.035671e-01  4.621982e-02    0.000219  1.642187e-05  ...   \n",
       "84402    0.049933  1.114182e-03  2.857292e-05    0.027544  2.605978e-04  ...   \n",
       "\n",
       "          ind_prod16  ind_prod17  ind_prod18  ind_prod19  ind_prod20  \\\n",
       "86466   1.904755e-07    0.000014    0.001201    0.000010    0.000002   \n",
       "73365   1.024248e-04    0.000373    0.050684    0.001055    0.000024   \n",
       "21207   6.667724e-02    0.000675    0.174465    0.204871    0.236651   \n",
       "93807   8.865389e-06    0.000675    0.011322    0.006860    0.001785   \n",
       "48285   1.909322e-07    0.000014    0.004141    0.000011    0.000002   \n",
       "125305  2.143078e-02    0.002750    0.118701    0.107853    0.052832   \n",
       "65848   1.904755e-07    0.000014    0.001201    0.000010    0.000002   \n",
       "93129   1.024248e-04    0.000373    0.050684    0.001055    0.000024   \n",
       "88807   1.111746e-02    0.001146    0.077085    0.095228    0.016989   \n",
       "84402   2.371912e-07    0.002750    0.017321    0.006308    0.004537   \n",
       "\n",
       "          ind_prod21  ind_prod22  ind_prod23  ind_prod24  ind_prod25  \n",
       "86466   7.687415e-14    0.000504    0.000778    0.003001    0.000012  \n",
       "73365   2.588881e-03    0.000932    0.001426    0.005181    0.000758  \n",
       "21207   9.471727e-03    0.181751    0.216862    0.377196    0.335571  \n",
       "93807   4.005483e-14    0.044988    0.044098    0.151164    0.009193  \n",
       "48285   3.851401e-14    0.000604    0.000717    0.003514    0.000010  \n",
       "125305  5.641094e-03    0.121113    0.129586    0.300861    0.160262  \n",
       "65848   7.687415e-14    0.000504    0.000778    0.003001    0.000012  \n",
       "93129   2.588881e-03    0.000932    0.001426    0.005181    0.000758  \n",
       "88807   1.683617e-07    0.158837    0.223802    0.402286    0.116910  \n",
       "84402   8.015374e-04    0.053569    0.072673    0.179578    0.011020  \n",
       "\n",
       "[10 rows x 24 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_gbdt[list(pred.columns)].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gbdt_product_recommender(df, cust_id, top_n):\n",
    "    \n",
    "    cust_id = str(cust_id)\n",
    "    prod_list=df.loc[df.index==cust_id,pred.columns].reset_index().T\n",
    "    prod_list.columns=['valor']\n",
    "    prod_list = prod_list.sort_values(by = 'valor', ascending = False)\n",
    "    \n",
    "    # Ouput the top N recommended products based on the customer's features. If the probability is lower than 0.5 do not output (the customer would not want this one)\n",
    "    prod_list = prod_list[prod_list['pred_score'] >= 0.001]\n",
    "    recommend_list = prod_list[0:top_n]\n",
    "    \n",
    "    while len(recommend_list) == 0:\n",
    "        print(\"Based on the customer's info, there is no bank product recommended for now\")\n",
    "        break\n",
    "    return recommend_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 0 elements, new values have 1 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgbdt_product_recommender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtest_gbdt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcust_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m73365\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_n\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[42], line 5\u001b[0m, in \u001b[0;36mgbdt_product_recommender\u001b[0;34m(df, cust_id, top_n)\u001b[0m\n\u001b[1;32m      3\u001b[0m cust_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(cust_id)\n\u001b[1;32m      4\u001b[0m prod_list\u001b[38;5;241m=\u001b[39mdf\u001b[38;5;241m.\u001b[39mloc[df\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m==\u001b[39mcust_id,pred\u001b[38;5;241m.\u001b[39mcolumns]\u001b[38;5;241m.\u001b[39mreset_index()\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m----> 5\u001b[0m \u001b[43mprod_list\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalor\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      6\u001b[0m prod_list \u001b[38;5;241m=\u001b[39m prod_list\u001b[38;5;241m.\u001b[39msort_values(by \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalor\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Ouput the top N recommended products based on the customer's features. If the probability is lower than 0.5 do not output (the customer would not want this one)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/pandas/core/generic.py:5915\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   5913\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   5914\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n\u001b[0;32m-> 5915\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__setattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5916\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m   5917\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/pandas/_libs/properties.pyx:69\u001b[0m, in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/pandas/core/generic.py:823\u001b[0m, in \u001b[0;36mNDFrame._set_axis\u001b[0;34m(self, axis, labels)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis: \u001b[38;5;28mint\u001b[39m, labels: AnyArrayLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    822\u001b[0m     labels \u001b[38;5;241m=\u001b[39m ensure_index(labels)\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[0;32m~/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/pandas/core/internals/managers.py:230\u001b[0m, in \u001b[0;36mBaseBlockManager.set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis: \u001b[38;5;28mint\u001b[39m, new_labels: Index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;66;03m# Caller is responsible for ensuring we have an Index object.\u001b[39;00m\n\u001b[0;32m--> 230\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_set_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis] \u001b[38;5;241m=\u001b[39m new_labels\n",
      "File \u001b[0;32m~/anaconda3/envs/entorno_prueba/lib/python3.11/site-packages/pandas/core/internals/base.py:70\u001b[0m, in \u001b[0;36mDataManager._validate_set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m new_len \u001b[38;5;241m!=\u001b[39m old_len:\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     71\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength mismatch: Expected axis has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements, new \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     72\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     73\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected axis has 0 elements, new values have 1 elements"
     ]
    }
   ],
   "source": [
    "gbdt_product_recommender(df = test_gbdt, cust_id = \"73365\", top_n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gbdt.to_csv('Predicciones.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>125305</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ind_prod1</th>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ind_prod3</th>\n",
       "      <td>0.709427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ind_prod4</th>\n",
       "      <td>0.001926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ind_prod5</th>\n",
       "      <td>0.172217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ind_prod6</th>\n",
       "      <td>0.034660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ind_prod7</th>\n",
       "      <td>0.023083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ind_prod8</th>\n",
       "      <td>0.229648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ind_prod9</th>\n",
       "      <td>0.082690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ind_prod10</th>\n",
       "      <td>0.002951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ind_prod11</th>\n",
       "      <td>0.003943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ind_prod12</th>\n",
       "      <td>0.069703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ind_prod13</th>\n",
       "      <td>0.181546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ind_prod14</th>\n",
       "      <td>0.036771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ind_prod15</th>\n",
       "      <td>0.007029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ind_prod16</th>\n",
       "      <td>0.021431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ind_prod17</th>\n",
       "      <td>0.002750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ind_prod18</th>\n",
       "      <td>0.118701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ind_prod19</th>\n",
       "      <td>0.107853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ind_prod20</th>\n",
       "      <td>0.052832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ind_prod21</th>\n",
       "      <td>0.005641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ind_prod22</th>\n",
       "      <td>0.121113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ind_prod23</th>\n",
       "      <td>0.129586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ind_prod24</th>\n",
       "      <td>0.300861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ind_prod25</th>\n",
       "      <td>0.160262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              125305\n",
       "ind_prod1   0.000014\n",
       "ind_prod3   0.709427\n",
       "ind_prod4   0.001926\n",
       "ind_prod5   0.172217\n",
       "ind_prod6   0.034660\n",
       "ind_prod7   0.023083\n",
       "ind_prod8   0.229648\n",
       "ind_prod9   0.082690\n",
       "ind_prod10  0.002951\n",
       "ind_prod11  0.003943\n",
       "ind_prod12  0.069703\n",
       "ind_prod13  0.181546\n",
       "ind_prod14  0.036771\n",
       "ind_prod15  0.007029\n",
       "ind_prod16  0.021431\n",
       "ind_prod17  0.002750\n",
       "ind_prod18  0.118701\n",
       "ind_prod19  0.107853\n",
       "ind_prod20  0.052832\n",
       "ind_prod21  0.005641\n",
       "ind_prod22  0.121113\n",
       "ind_prod23  0.129586\n",
       "ind_prod24  0.300861\n",
       "ind_prod25  0.160262"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod_list = test_gbdt.loc[test_gbdt.index==125305,pred.columns].T\n",
    "prod_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "entorno_prueba",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
